#import "../module/module.typ": *
#show: module

One-dimensional separable variable ODE
$
  (#d x)/(#d t) = f(t) g(x)
  &--> 1/g(x) #d x = f(t) #d t \
  &--> x = G^(-1)(F(t))
$
where $G = integral 1/g(x) #d x, F = integral f(t) #d t$, initial value undecided

*Example*
- $f(t) = a, g(x) = x, (#d x)/(#d t) = a x$. $x(t) = x(0) exp(a t)$

- $f(t) = 1, g(x) = x^2, (#d x)/(#d t) = x^2$. $x(t) = 1/(1/x(0) - t)$

#tag("exponential-of-vector-field") *Question*
#indent[
  let $U$ open in $‚Ñù^n$

  The vector field is an analytic function $v : U -> ‚Ñù^n$

  If you know matrix Lie groups, then you should know that Lie algebras can be mapped to Lie groups via $exp$
  $
    exp: dmat( delim: #none ,
      g &‚ü∂ G ;
      X &‚üø sum_(n =  0)^‚àû X^n/n!
    )
  $
  This also holds for analytic functions; in the sense of analytic topological convergence, $exp v$ should generate a local analytic diffeomorphism. The value of $exp v$ at $x$ should be
  $
    (exp v) (x)
    &= (sum_(n=0)^‚àû v^n/(n!)) (x) \
    &= x + v(x) + 1/2! v(x)^2 + ‚ãØ
  $
  $n$ polynomial like $(Œª v(x))^n = Œª^(n) (v(x)^n)$

  Or adding $t$
  $
    (exp t v) (x)
    &= x + t v(x) + t^2/2! v(x)^2 + ‚ãØ
  $
  Such that it corresponds to the ODE $‚àÇ_t (exp t v) (x) = v((exp t v) (x))$. We know that ODE theory can also give local diffeomorphisms through vector fields
]
*Example*

Comparing the results of pure vector fields to the results of ODE integral curves, you will find the results are the same. Take the case of constant coefficient linear or one-dimensional separable ODEs as an example

- $v(x) = A(x) equiv A in gl(d,ùïÇ)$
#indent[
  compare $vel(x) = A x$, expect $(sum_(0..‚àû) 1/n! (A t)^n)(x)$ with $t = 1$

  $f(t,x) = (ùüô + t A + t^2/2! A^2 + ‚ãØ) (x) = (sum t^n/n! A^n ) (x) = (exp t A) (x)$

  *Example* #tag("harmonic-oscillator")
  #indent[
    Harmonic oscillator $acc(x) = ‚àì œâ^2 x$ first-orderized
    $
      mat((#d)/(#d t) ; , (#d)/(#d t)) vec(x,v) = mat(, 1 ; ‚àì œâ^2) vec(x,v)
    $
    Trigonometric case takes $- œâ^2$
    $
      exp t mat(, 1 ; - œâ^2) = mat(
        cos œâ t , 1/œâ sin œâ t ;
        - œâ sin œâ t , cos œâ t
      )
    $
    Thus
    $
      x(t) = x_0 cos œâ t + v_0/œâ sin œâ t
    $
    Or written in the form of complex exponentials
    $
      x(t) = 1/2 (x_0 - #i v_0/œâ) e^(#i œâ t) + 1/2 (x_0 + #i v_0/œâ) e^(- #i œâ t) =: a (œâ, #i) e^(#i œâ t) + a (œâ, -#i) e^(- #i œâ t)
    $
    Hyperbolic case takes $+ œâ^2$, similarly

    The characteristic polynomial equation of the harmonic oscillator equation is $Œæ^2 ¬± œâ^2 = 0$ or $Œæ^2 = ¬± œâ^2$. We are interested in the trigonometric case $Œæ^2 + œâ^2 = 0$ or $Œæ = ¬± #i œâ$, whose prototype is $Œæ^2 = - 1$ or $Œæ^2 = ¬± #i$. This gives a motivation for complex numbers

    In the case where the harmonic oscillator $x$ is a real-valued function, in the complex exponential representation of the solution, to keep the result in $‚Ñù$, when $x_0,v_0 in ‚Ñù$, the coefficients in front of $e^(¬± #i œâ t)$ should be complex conjugates of each other $x_0 ¬± (v_0)/(#i œâ)$
  ]
]
- $‚Ñù -> ‚Ñù$, $v(x) = x^2$
#indent[
  compare $vel(x) = x^2$, expect $1/(1/x - t)$ with $t = 1$

  $v(x)^2 = v'(x) v(x) = 2 ‚ãÖ x^3$

  $v(x)^3 = (2 x^3)' v(x) = (2 ‚ãÖ 3) ‚ãÖ x^4$

  ...

  $v(x)^n = n! ‚ãÖ x^(n+1)$

  $v(x)^n / n! = x^(n+1)$

  $(exp v)(x)
  &= sum_(m=1)^‚àû x^m \
  &= 1/(1-x) - 1$

  Or

  $(t^n v(x)^n) / n! = t^n x^(n+1)$

  $(exp t v)(x)
  &= 1/t sum_(m=1)^‚àû (t x)^m \
  &= 1/t (1/(1 - t x) - 1) \
  &= 1/t ((t x)/(1 - t x)) \
  &= 1/(1/x - t)$
]
#tag("vector-field-as-Œ¥-diffeomorphism") Near the local analytic homeomorphism $ùüô$, the vector field $v$ serves as the coordinate of the local analytic homeomorphism group $v ‚áù exp v$. This is similar to #link(<geodesic-coordinate>)[]

ODE, it's also a one-parameter homomorphism embedding $(exp t v)(x) : ‚Ñù ‚Ü™ "Loc_diff"$

$ (#d)/(#d t) (exp t v) (x) = v((exp t v) (x)) $

Usually denoted as $x(t) = (exp t v)(x_0), x(0) = x_0$

For proof techniques, see #link("https://en.wikipedia.org/wiki/Cauchy-Kovalevskaya_theorem")[wiki:Cauchy-Kovalevskaya_theorem], where the convergence radius of the power series is estimated using a special upper bound control method, similar to what was done in #link(<inverse-analytic>)[]

$F(x_0, x) = (c x_0)/(x_0 - x)$, $(#d x)/(#d t) = F(x_0, x)$ ==> $x(t, x_0) = x_0 - (x_0^2 - 2 c t x_0)^(1/2)$

#tag("integral-curve") Picard iteration (#link("https://en.wikipedia.org/wiki/Picard‚ÄìLindel√∂f_theorem")[wiki]) representation of ODE solutions or integral curves e.g.
$
  x(t) = sum_(n = 0 .. ‚àû) integral_(0)^(t) #d t_(n) integral_(0)^(t_n) #d t_(n-1) ‚ãØ integral_(0)^(t_0) #d t_1 v( ‚ãØ v(x(0)) ‚ãØ )
$
A time-varying vector field ODE is a special kind of vector field $(1, v(x))$ on $‚Ñù √ó ‚Ñù^n$

If it is a time-varying linear ODE then (*alias* Dyson series)
$
  x(t) = sum_(n = 0 .. ‚àû) integral_(0)^(t) #d t_(n) integral_(0)^(t_n) #d t_(n-1) ‚ãØ integral_(0)^(t_0) #d t_1 A(t_n) ‚ãØ A(t_1) x(0)
$
The solution to a constant coefficient ODE $((#d^n)/(#d t^n) + a_(n-1) (#d^(n-1))/(#d t^(n-1)) + ‚ãØ + a_0) x = 0$ can be written in analytic form, by converting the ODE into a first-order constant coefficient linear ODE $(#d)/(#d t) y = A y$ regarding $y = (x, (#d)/(#d t) x ,‚Ä¶, (#d^n)/(#d t^n) x)$, and then writing matrix $A$ in Jordan normal form

#tag("Lie-bracket") Lie bracket
#indent[
  The #link(<conjugate-action>)[] of $"Diff"$ $(f,g) ‚áù f g f^(-1)$

  Suppose $v, w$ generate $f, g$. The first-order derivative is $(v, w) ‚áù w$, while the second-order derivative mixing $v, w$ is $(v, w) ‚áù "ad"(v)(w) = [v,w]$, which can also be understood as $w$ first then $v$, so that a "linear representation of the Lie group" $"Ad"$ is obtained midway

  Note that after swapping the order of $g,f$, $(g,f) ‚áù g f g^(-1)$ is a different mapping

  $[v,w](x) = v(x) w(x) - w(x) v(x)$

  $[v,w] = -[w,v]$

  for $GL,gl$, $[A,B] ‚àº A B - B A$
]
#let L = c-diff($L$)
#tag("Lie-derivative") Lie derivative *alias* drag derivative
#indent[
  let $v$ generate a one-parameter diffeomorphism $t ‚áù exp(t v) = f_t in "Diff"$ through $t v$

  let $w_t = #d f_(t)^(-1) (f_t (x) : "base", w(f_t (x)) : "vector")$

  $#L _v (w) := lim_(t -> 0) 1/t (w_t - w_0) $

  $#L _v (w) = [v,w]$

  Jacobi identity $#L _([v,w]) = [#L _v,#L _w]$ or $[v_1,[v_2,w_3]] + [v_3,[v_1,v_2]] + [v_2,[v_3,v_1]] = 0$

  The Lie derivative can also be defined for tensor fields ...
]
#tag("first-order-PDE-integrable-condition") *alias* #tag("Frobenius-theorem") generalizes first-order ODE integral curves to first-order PDE system integral surfaces; in this case, the linear space spanned by the vector fields $v_1 ,‚Ä¶, v_n$ needs to form a Lie subalgebra, or use the more general concept of involutive/integrable subbundles. Solutions to the PDE can come from successive ODE integral curves along coordinate directions, and the result doesn't depend on the choice of path. In the case of first-order linear PDE systems, the integrability condition becomes the symmetry of second-order partial derivatives under coordinates